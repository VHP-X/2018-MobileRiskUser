### 模型解释文档

#### 模型概述

整个模型是由 `xgboost, lightgbm ` 两种模型融合而成的。 其中每种中又包含10个子模型做融合。

建立模型的大致过程： 

1. 以 单`xgb`为基础， 在此基础上通过`kfold = 3` 的 *cv* 来评估当前特征的好坏，进行必要的特征提取与筛选，
2. 之后进行调试参数， 主要也是以线下*cv*为主要依据。
3. 在调参过程大致结束后， 再用同样的操作构建`lgb`模型。
4. 通过 `feature_fraction` 来使`xgb， lgb`得到 10个子模型
5. 最后采用加权融合的方式将两者结合起来， 配以适当的权值， 得到最终的模型

#### 重要特征

事实上， 虽然采用的是树集成模型，可解释性较强， 但是我还是觉得只靠其提供的 `feature_importance` 接口， 并不能够完全反映问题： 这里反映出的是单特征的重要性，但是没有考虑到特征之间组合之后的强相关性。因此我先放上由 `lgb`的`feature_importance`提供的重要性排名，  接下来说一些我自己认为较为重要的特征。

feature_importance:

![](.\feature_importance.png)

对应的特征名称的具体含义在代码中一一有注释。

我自己认为比较重要的特征（族）：

1. 通话的`opp_head` 分类， 分 in out 统计；
2. 短信的`opp_head` 分类， 分 in out 统计；
3. 按照运营商来分类常见的`opp_head`, 再根据分类结果进行统计。
4. 对通话时间量的相关统计

这几点是我通过不断改进过程中的线上分数提升总结得到的。



#### 特征处理方式

虽然这次我的模型包含1700多个特征，但是提取的方法很有限， 无外乎以下几种;

1. 对二值信息做大量特征组合。这里指 `sms， voice` 中的 `in/out` 信息， 以及 `wa` 中的 `web/app`信息。事实上在比赛后期， 我一度觉得， 应该直接把 `sms，voice` 直接根据 `in/out`分成两个表来处理， 因为几乎我提取的大部分特征都是做了 `in/out`组合的
2. 对比较少量取值空间的信息， 如 `sms`和`voice`的`opp_head` 信息， 甚至`sms`的`opp_num`, 直接对其做`one_hot` 处理——可以直接得到大量特征，但是很有过拟合的风险， 这个可以通过对模型的参数设置得到比较好的解决。
3. 对于大量取值空间的信息，如 `voice`的`opp_num`, 以及`wa_name`， 对每个值的出现频率进行统计， 再取出现频率的前 `Top-K` 进行`one-hot`, 剩余的全部归到一个类别中。
4. 根据实际生活经验提取。这个就比较抽象了。 举个例子： 比如可以根据`opp_head`, 查到该号码的运营商， 再依此分类。再比如处理时间信息的时候，可以根据人的生活规律来进行分类统计，分成： 8点之前， 8-12点， 12-14点， 14-17点， 17点之后 这样。



#### 几个提分点

这里指的提分点不包含特征， 指的是除了特征工程之外的提分点。

1. 可以看到这次给出的正负样本数还是有所差异的， 为了平衡这一点， 在评估函数内适当调小阈值，可以获得更好的的结果；
2. *fillna or not， and type？* 这是一个小细节， 因为`xgb，lgb`支持特征矩阵中含有`NA`， 具体该不该填， 填什么， 都是根据本地cv来确定。 同理， 对于数据要不要取整， 哪些数据要取整， 也是看cv的结果。
3. 注意通过控制阈值来提高F1值。 这个就没什么好说，就是调参
4. **通过利用初赛数据集来提高复赛数据集上的表现。 个人感觉这是一个比较新颖的特点。**之所以想到这一点是考虑到这次的训练id和测试id比起来显得有点少，因此希望尽量多的采集到数据——初赛测试数据集就是不错的选择。 （不过最好需要在初赛榜上有不错的成绩）
5. 在模型融合时填入合适的权值。这个也没什么好说， 也是参数调整。